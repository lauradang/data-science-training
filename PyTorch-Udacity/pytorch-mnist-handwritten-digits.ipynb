{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch-mnist-handwritten-digits.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOcn1X2kw3RrGRdgEcvVU4B"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2WIpk-TpZV7o","colab_type":"text"},"source":["# Multilayer Neural Networks in Pytorch\n","Pytorch has a module called `nn` that has a lot of classes and functions to build large neural networks efficiently."]},{"cell_type":"code","metadata":{"id":"R94wH-pFKBj_","colab_type":"code","colab":{}},"source":["import torch\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"99xfY0EWfmSM","colab_type":"code","colab":{}},"source":["def sigmoid(x):\n","  \"\"\"\n","  Sigmoid activation function.\n","\n","  Parameters:\n","    x: The torch.Tensor\n","  \"\"\"\n","  return 1/(1+torch.exp(-x))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IDOYhaQVczT2","colab_type":"text"},"source":["## Load the dataset from Pytorch"]},{"cell_type":"code","metadata":{"id":"1ZLgHs8WZVCU","colab_type":"code","colab":{}},"source":["from torchvision import datasets, transforms\n","\n","transform = transforms.Compose([\n","  transforms.ToTensor(), \n","  transforms.Normalize((0.5, ), (0.5, ))\n","])\n","\n","trainset = datasets.MNIST(\n","    \"MNIST_data/\", \n","    download=True, \n","    train=True, \n","    transform=transform\n",")\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sdVEHoYZbtq7","colab_type":"text"},"source":["## Iterating through images from MNIST dataset\n","You can iterate through the image and labels by using:\n","```python\n","for image, label in trainloader:\n","  print(image, label)\n","```\n","Since we set the batch size to 64, we get 64 images per iteration (explains the output of `images.shape`)."]},{"cell_type":"code","metadata":{"id":"37KI_5uqZYkc","colab_type":"code","outputId":"6eb5401b-051b-41e4-8cc8-c1e87af7e085","executionInfo":{"status":"ok","timestamp":1584314028399,"user_tz":240,"elapsed":3143,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["data_iterate = iter(trainloader)\n","images, labels = data_iterate.next()\n","print(type(images))\n","print(images[0].shape)\n","print(images.shape)\n","print(labels.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","torch.Size([1, 28, 28])\n","torch.Size([64, 1, 28, 28])\n","torch.Size([64])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fe2L4cXUbSH-","colab_type":"code","outputId":"1508c402-dfd7-4b3a-9628-04fcbf1cc56e","executionInfo":{"status":"ok","timestamp":1584314028399,"user_tz":240,"elapsed":3128,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["plt.imshow(images[63].numpy().squeeze())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fe9af47fc50>"]},"metadata":{"tags":[]},"execution_count":69},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"4U-3Bapmc8JI","colab_type":"text"},"source":["## Implementing the Multilayer Neural Network\n","- 784 input units\n","  - **Justification**: Each image is (28x28), so our input units are actually a 2D matrixes of (28x28). We need the each image to be a 1D vector. So if we were to flatten these 2D matrixes, each image would be a (1x784) 1D matrix since $28*28=784$. So now, since we have 64 images per batch size, the overall input shape to the network would be (64x784). Essentially, we have 64 images, and each image is a 1D vector.\n","- 256 hidden units\n","- 10 output units (we have 10 classes)"]},{"cell_type":"code","metadata":{"id":"EdVkTC-yfV3R","colab_type":"code","colab":{}},"source":[" # Set seed so data is consistent \n","torch.manual_seed(7)\n","\n","# Flattens input images to (64, 784)\n","# Equivalent to images.view(64, 28*28)\n","# -1 means that this dimension can be figured out with the first dimension\n","features = images.view(images.shape[0], -1)\n","\n","num_input = features.shape[1]\n","num_hidden = 256\n","num_output = 10\n","\n","w1 = torch.randn(num_input, num_hidden) \n","w2 = torch.randn(num_hidden, num_output)\n","\n","b1 = torch.randn(num_hidden) # can also do (1, num_hidden), but this is shorter\n","b2 = torch.randn(num_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vApbcyZgx7W","colab_type":"code","colab":{}},"source":["layer1 = sigmoid(torch.mm(features, w1) + b1)\n","output = torch.mm(layer1, w2) + b2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLnWHfRbiakn","colab_type":"code","outputId":"8c50228a-a14e-433e-b43b-1d474a665e54","executionInfo":{"status":"ok","timestamp":1584314028404,"user_tz":240,"elapsed":3092,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["output.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 10])"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"X3TM1azgjG6s","colab_type":"text"},"source":["### Using Softmax to find Probability Distribution of the Classes\n","Softmax Function: $\\sigma(x_i)=\\frac{e^{x_i}}{\\Sigma_k^K e^{x_k}}$\n","\n","To classify an object, we take the highest probable class that was detected by the model. Remember that the model doesn't actually output a classification, it outputs probabilities and we just take the highest one to find the predicted class.\n","\n","- `dim=0` refers to rows\n","- `dim=1` refers to columns\n","- `torch.sum(x, dim=0/1)` refers to summing across all rows/columns"]},{"cell_type":"code","metadata":{"id":"8uNIExpVmakl","colab_type":"code","outputId":"d6000284-a36f-4bcb-bf23-a6fe60424d4f","executionInfo":{"status":"ok","timestamp":1584314028405,"user_tz":240,"elapsed":3052,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["output[0] # there are 64 tensors like this"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ -5.2570,  -7.7674,  -2.4731,  -7.8444,  10.1712,   6.5950, -12.3128,\n","          3.1289, -14.6970,   3.2137])"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"mVecggscn4tL","colab_type":"code","outputId":"11d08851-50c7-4380-b77e-12921f89322c","executionInfo":{"status":"ok","timestamp":1584314028405,"user_tz":240,"elapsed":3036,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.sum(torch.exp(output), dim=1).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64])"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"markdown","metadata":{"id":"zXrPAdQ_odyd","colab_type":"text"},"source":["`torch.sum(torch.exp(x), dim=1)`: vector of 64 elements (1, 64)`torch.exp(x)`: (64, 10)\n","We want output to be 64x10. So need to reshape using `.view(-1, 1)`."]},{"cell_type":"code","metadata":{"id":"CnG8dnBUjlZb","colab_type":"code","colab":{}},"source":["def softmax(x):\n","  return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hXtK5JTk_U9","colab_type":"code","outputId":"58e2a707-456f-453d-ce25-8ae392ee5b7c","executionInfo":{"status":"ok","timestamp":1584314028406,"user_tz":240,"elapsed":3015,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["softmax(output).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 10])"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"mOGl1gwllH0-","colab_type":"code","outputId":"71f7fcfb-eca8-4460-bf5e-41bfc225dcb9","executionInfo":{"status":"ok","timestamp":1584314028407,"user_tz":240,"elapsed":3006,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["softmax(output).sum(dim=1)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000])"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"markdown","metadata":{"id":"_4jRxSA1o5eg","colab_type":"text"},"source":["## Implementing the Multilayer Neural Network using `nn`\n","We can implement the same NN as above but using the `nn` library.\n","The neural network will have:\n","- 784 input units\n","- 256 hidden units\n","- 10 output units\n","- softmax output\n","\n","### Creating the class\n","1. Create a class that inherits from the provided `nn.Module` class.\n","2. Initialize the class using `super()` to ensure the `nn.Module` class has also been intialized in the constructor. This ensures all the operations from `torch` we use are recognized in the `Network` class.\n","\n","### Creating the network layers\n","- `nn.Linear(# of inputs, # of outputs)`: Automatically calculates linear transformation and creates its own weights and bias. Essentially, we no longer have to define the weights and bias manually anymore like before.\n"]},{"cell_type":"code","metadata":{"id":"OkYKTYURo2b0","colab_type":"code","colab":{}},"source":["from torch import nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYLCjP1KpH5G","colab_type":"code","colab":{}},"source":["class Network(nn.Module): \n","  def __init__(self):\n","    super().__init__()\n","\n","    # Compare this to the line where we created w1\n","    self.hidden = nn.Linear(784, 256) # 784 is # of inputs, 256 is # of outputs\n","    self.output = nn.Linear(256, 10)\n","\n","    self.sigmoid = nn.Sigmoid()\n","    self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x): \n","      \"\"\"\n","      Passes the input tensor through each operation defined in the class\n","\n","      Parameters:\n","        x: The input tensor.\n","      \n","      Returns the output tensor\n","      \"\"\"\n","      x = self.hidden(x)\n","      x = self.sigmoid(x)\n","      x = self.output(x)\n","      x = self.softmax(x)\n","\n","      return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jo5114eFrR3y","colab_type":"code","outputId":"fb88ed11-1ada-4183-f96f-d7cd6e3ebf65","executionInfo":{"status":"ok","timestamp":1584314028409,"user_tz":240,"elapsed":2952,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["model = Network()\n","model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Network(\n","  (hidden): Linear(in_features=784, out_features=256, bias=True)\n","  (output): Linear(in_features=256, out_features=10, bias=True)\n","  (sigmoid): Sigmoid()\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"markdown","metadata":{"id":"YueDDgiRr8rg","colab_type":"text"},"source":["### Alternative Model using `nn.functional`\n","We can also use this library to clean up our class a bit."]},{"cell_type":"code","metadata":{"id":"Oyq_UQ9bsBlB","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F\n","\n","class Network(nn.Module): \n","  def __init__(self):\n","    super().__init__()\n","\n","    self.hidden = nn.Linear(784, 256)\n","    self.output = nn.Linear(256, 10)\n","\n","    def forward(self, x): \n","      \"\"\"\n","      Passes the input tensor through each operation defined in the class.\n","\n","      Parameters:\n","        x: The input tensor.\n","      \n","      Returns The output tensor.\n","      \"\"\"\n","      x = F.sigmoid(self.hidden(x))\n","      x = F.softmax(self.output(x), dim=1)\n","\n","      return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvLvKOMdsPyk","colab_type":"code","outputId":"9bc8ba4d-f66f-478e-930f-5406027c9a60","executionInfo":{"status":"ok","timestamp":1584314028411,"user_tz":240,"elapsed":2804,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["model = Network()\n","model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Network(\n","  (hidden): Linear(in_features=784, out_features=256, bias=True)\n","  (output): Linear(in_features=256, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"markdown","metadata":{"id":"4wVEda-ssttL","colab_type":"text"},"source":["## Building my own Network\n","1. **Input layer**: 784 input neurons\n","2. **Hidden layer 1**: 128 neurons (relu)\n","3. **Hidden layer 2**: 64 neurons (relu)\n","4. **Output layer**: 10 neurons (softmax)\n","5. **Loss Layer**: Cross-entropy"]},{"cell_type":"code","metadata":{"id":"DkeQNS1stIOW","colab_type":"code","colab":{}},"source":["class Network(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.hidden1 = nn.Linear(784, 128)\n","    self.hidden2 = nn.Linear(128, 64)\n","    self.output = nn.Linear(64, 10)\n","\n","  def forward(x, self):\n","    \"\"\"\n","    Passes the input tensor through each operation defined in the class.\n","\n","    Parameters:\n","      x: The input tensor.\n","\n","    Returns:\n","      The output tensor which contains the probabilities distributions of the\n","      classes of the image.\n","    \"\"\"\n","    x = F.Relu(self.hidden1)\n","    x = F.Relu(self.hidden2)\n","    x = F.Softmax(self.output)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDw-2nzJt3Ml","colab_type":"code","outputId":"b867acfd-3d13-4afe-8f3c-560cd38c4737","executionInfo":{"status":"ok","timestamp":1584314028412,"user_tz":240,"elapsed":2740,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["model = Network()\n","model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Network(\n","  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n","  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n","  (output): Linear(in_features=64, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"gmvdLMuyKlYa","colab_type":"text"},"source":["# Calculating Loss in Pytorch\n","\n","You need to define a variable (typically called `criterion`) with a loss from the `nn` library. In this case, we use `nn.NLLLoss()`. Then we feed the output of the foward pass (probability distributions from softmax) and the labels of the images to `criterion`."]},{"cell_type":"code","metadata":{"id":"_ix24K0Lt7zu","colab_type":"code","outputId":"debb8cbd-6b11-4e89-d8b6-05f0c514e880","executionInfo":{"status":"ok","timestamp":1584314028413,"user_tz":240,"elapsed":2725,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model = nn.Sequential(\n","    nn.Linear(784, 128),\n","    nn.ReLU(),\n","    nn.Linear(128, 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 10),\n","    nn.LogSoftmax(dim=1)\n",")\n","\n","# Defining the loss\n","criterion = nn.NLLLoss()\n","\n","# Retrieve the data\n","images, labels = iter(trainloader).next()\n","\n","# Flatten the images\n","images = images.view(images.shape[0], -1)\n","\n","# Forward pass\n","probabilities = model(images)\n","\n","# Calculate loss\n","loss = criterion(probabilities, labels)\n","loss"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.2781, grad_fn=<NllLossBackward>)"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"markdown","metadata":{"id":"YFuT6RCxM8tC","colab_type":"text"},"source":["## Autograd\n","Automatically calculates gradient on a tensor. Pytorch keeps track of the operations done on a tensor, and then `autograd` will use chainrule and derivatives to calculate the gradients backwards (does backpropogation for you).\n","\n","Ways to enable `autograd`:\n","\n","1. Set parameter `requires_grad=True` when creating a tensor.\n","2. Use `with torch.no_grad()`, anything within its context will use `autograd`.\n","3. **GLOBALLY**: `torch.set_grad_enabled(True|False)`"]},{"cell_type":"markdown","metadata":{"id":"aEucC7kjPHGK","colab_type":"text"},"source":["`y.grad_fn` returns the operation performed on `y`, so we can see here that Pytorch is keeping track of the operations done on the tensor."]},{"cell_type":"code","metadata":{"id":"gh0MB87iOcZW","colab_type":"code","outputId":"0bde7797-b230-44d2-f35a-b30f18614a87","executionInfo":{"status":"ok","timestamp":1584314028413,"user_tz":240,"elapsed":2713,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x = torch.randn((2, 2), requires_grad=True)\n","y = x**2\n","y.grad_fn"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PowBackward0 at 0x7fe9aee13668>"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"thsXSeY2Pir9","colab_type":"text"},"source":["The gradient of `x` right now is `None`"]},{"cell_type":"code","metadata":{"id":"AxtTSKq_PXZT","colab_type":"code","outputId":"7d90b6e2-65a2-4030-e1cd-0e8e9ecf50bc","executionInfo":{"status":"ok","timestamp":1584314028414,"user_tz":240,"elapsed":2701,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(x.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yUYYLaMjPZ-t","colab_type":"code","colab":{}},"source":["z = y.mean()\n","z.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ciuTs9GQGvg","colab_type":"text"},"source":["So now, after using `.backward()`. We can see that `x.grad` has a gradient now. Let's see if it's correct.\n","\n","$$\\frac{\\partial z}{\\partial x}=\\frac{\\partial}{\\partial x}[\\frac{1}{n}\\Sigma x_i^2]=\\frac{x}{2}$$\n","- $\\frac{1}{n}$ comes from the `y.mean()` operation.\n","- Squaring x comes from `x**2`.\n","\n","So since `x.grad == x/2` is True. We can see that the `.backward()` function was correct."]},{"cell_type":"code","metadata":{"id":"i1OGPdZwP5q2","colab_type":"code","outputId":"15d9db0f-a40f-4c6f-cbf3-ec1107ad9422","executionInfo":{"status":"ok","timestamp":1584314028416,"user_tz":240,"elapsed":2673,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["x.grad == x/2"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[True, True],\n","        [True, True]])"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"TBr5blqHP6Uq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6jR8yyY2Ri-Q","colab_type":"text"},"source":["## Putting Loss and Autograd Together\n","**Review**:\n","- Loss dependent on weights and bias - $L(w_1, w_2, b_1, b_2)$\n","- Gradient descent needs gradients"]},{"cell_type":"code","metadata":{"id":"MbJhf87XSHip","colab_type":"code","colab":{}},"source":["model = nn.Sequential(\n","    nn.Linear(784, 128),\n","    nn.ReLU(),\n","    nn.Lineaxr(128, 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 10),\n","    nn.LogSoftmax(dim=1)\n",")\n","\n","criterion = nn.NLLLoss()\n","images, labels = iter(trainloader).next()\n","images = images.view(images.shape[0], -1)\n","\n","# Forward pass\n","probabilities = model(images)\n","\n","# Calculate loss\n","loss = criterion(probabilities, labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nHoj3EiSg-R","colab_type":"code","outputId":"08620efd-a060-4cf6-8852-afd103673c37","executionInfo":{"status":"ok","timestamp":1584314029017,"user_tz":240,"elapsed":3229,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["print(f\"Before backward pass: {model[0].weight.grad}\")\n","loss.backward()\n","print(f\"After backward pass: {model[0].weight.grad}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Before backward pass: None\n","After backward pass: tensor([[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n","        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n","        [-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001],\n","        ...,\n","        [ 0.0029,  0.0029,  0.0029,  ...,  0.0029,  0.0029,  0.0029],\n","        [ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010],\n","        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DW7Zq1YSS-vw","colab_type":"text"},"source":["## Optimizer\n","So now that we have the gradients, how can we use these gradients to update our weights during training? Optimizers! We can use the `optim` package.\n","\n","`optim.SGD(parameters, lr=lr)`: `parameters` are the weights/parameters we want to update, `lr` is the learning rate $\\alpha$.\n","\n","**IMPORTANT**: You have to remember to clear the gradients using `optimizer.zero_grad()`. Otherwise, the gradients will accumulate and you will not get the correct gradients."]},{"cell_type":"code","metadata":{"id":"sWou2dz8Sr8y","colab_type":"code","colab":{}},"source":["from torch import optim\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7B2hnU8HT1jH","colab_type":"code","outputId":"0f1c0c49-de9c-49ec-93c1-460a5d1a0f6e","executionInfo":{"status":"ok","timestamp":1584314029019,"user_tz":240,"elapsed":3163,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"source":["print(f\"Initial weights: {model[0].weight}\")\n","\n","images, labels = iter(trainloader).next()\n","\n","# Equivalent to images = images.view(images.shape[0], -1)\n","images.resize_(64, 784)\n","\n","# Clears the gradients\n","optimizer.zero_grad() \n","\n","# Equivalent to model(images)\n","output = model.forward(images)\n","loss = criterion(output, labels)\n","loss.backward()\n","print(f\"Gradient: {model[0].weight.grad}\")\n","optimizer.step()\n","print(f\"Updated Weights: {model[0].weight}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initial weights: Parameter containing:\n","tensor([[ 0.0149,  0.0095, -0.0075,  ...,  0.0132,  0.0239,  0.0199],\n","        [-0.0123, -0.0345,  0.0167,  ..., -0.0143,  0.0217, -0.0162],\n","        [ 0.0228,  0.0204,  0.0292,  ...,  0.0244, -0.0111, -0.0224],\n","        ...,\n","        [ 0.0008, -0.0038, -0.0120,  ..., -0.0128,  0.0232,  0.0235],\n","        [-0.0170, -0.0241,  0.0197,  ...,  0.0026, -0.0038, -0.0149],\n","        [-0.0324,  0.0095,  0.0235,  ..., -0.0300,  0.0024, -0.0320]],\n","       requires_grad=True)\n","Gradient: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00],\n","        [ 1.0305e-04,  1.0305e-04,  1.0305e-04,  ...,  1.0305e-04,\n","          1.0305e-04,  1.0305e-04],\n","        [-3.9194e-04, -3.9194e-04, -3.9194e-04,  ..., -3.9194e-04,\n","         -3.9194e-04, -3.9194e-04],\n","        ...,\n","        [ 1.7331e-03,  1.7331e-03,  1.7331e-03,  ...,  1.7331e-03,\n","          1.7331e-03,  1.7331e-03],\n","        [-8.4655e-04, -8.4655e-04, -8.4655e-04,  ..., -8.4655e-04,\n","         -8.4655e-04, -8.4655e-04],\n","        [ 8.8178e-05,  8.8178e-05,  8.8178e-05,  ...,  8.8178e-05,\n","          8.8178e-05,  8.8178e-05]])\n","Updated Weights: Parameter containing:\n","tensor([[ 0.0149,  0.0095, -0.0075,  ...,  0.0132,  0.0239,  0.0199],\n","        [-0.0123, -0.0345,  0.0167,  ..., -0.0143,  0.0217, -0.0162],\n","        [ 0.0228,  0.0204,  0.0292,  ...,  0.0244, -0.0111, -0.0224],\n","        ...,\n","        [ 0.0008, -0.0038, -0.0120,  ..., -0.0129,  0.0232,  0.0235],\n","        [-0.0170, -0.0241,  0.0197,  ...,  0.0026, -0.0038, -0.0149],\n","        [-0.0324,  0.0095,  0.0235,  ..., -0.0300,  0.0024, -0.0320]],\n","       requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T1iMqiMuY-IA","colab_type":"text"},"source":["## Training the Neural Network\n","\n","So here's the high level process we want to follow:\n","\n","1. Set up weights as tensors that require gradients\n","2. Do forward pass to calculate loss\n","3. With this calculated loss, do backward pass on it to calculate gradients \n","4. With these gradients, calculate gradient descent.\n","5. With the gradients, use an optimizer to update the weights."]},{"cell_type":"markdown","metadata":{"id":"o0zMuLGdZvcD","colab_type":"text"},"source":["### Initializing Variables used for Training"]},{"cell_type":"code","metadata":{"id":"X1eUU0JYZA_1","colab_type":"code","colab":{}},"source":["model = nn.Sequential(\n","    nn.Linear(784, 128),\n","    nn.ReLU(),\n","    nn.Linear(128, 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 10),\n","    nn.LogSoftmax(dim=1)\n",")\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.003)\n","epochs = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C0SjAVSfZgzs","colab_type":"code","outputId":"2a8b9f3f-9cfe-4ce1-8e45-2a310033f9a9","executionInfo":{"status":"ok","timestamp":1584314073877,"user_tz":240,"elapsed":47995,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["from tqdm import tqdm\n","\n","for i in tqdm(range(epochs), desc=\"Epoch\"):\n","  running_loss = 0\n","  for images, labels in trainloader:\n","    images = images.view(images.shape[0], -1)\n","\n","    optimizer.zero_grad() \n","    output = model.forward(images)\n","    loss = criterion(output, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","  else:\n","    print(f\" Training loss: {running_loss/len(trainloader)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch:  20%|██        | 1/5 [00:09<00:37,  9.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":[" Training loss: 1.8267695743646195\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  40%|████      | 2/5 [00:18<00:27,  9.33s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":[" Training loss: 0.805294813727265\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  60%|██████    | 3/5 [00:27<00:18,  9.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":[" Training loss: 0.5084165562825925\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  80%|████████  | 4/5 [00:36<00:09,  9.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":[" Training loss: 0.4209665475782555\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 5/5 [00:45<00:00,  9.21s/it]\u001b[A\n","\u001b[A"],"name":"stderr"},{"output_type":"stream","text":[" Training loss: 0.379444205764133\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ENJF6_YBc9Pp","colab_type":"text"},"source":["## Predictions on the Model"]},{"cell_type":"code","metadata":{"id":"aCZ6DgnrcT_G","colab_type":"code","outputId":"ac078a42-612b-467c-aed4-e137d2668e01","executionInfo":{"status":"ok","timestamp":1584314073878,"user_tz":240,"elapsed":47966,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["%matplotlib inline\n","import numpy as np\n","\n","images, labels = next(iter(trainloader))\n","\n","# Turn off gradients to save processing power (don't need backward pass)\n","with torch.no_grad():\n","  # Need to reshape 28x28 image to 1x784 to fit input shape\n","  output = model.forward(images[0].view(1, 784))\n","\n","# Output of network are logists\n","output"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ -0.0429, -19.8324, -11.5615,  -8.9620, -16.4571,  -3.1834, -13.5901,\n","         -13.3725,  -7.7377, -12.2995]])"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"AcZKKAF8ccKJ","colab_type":"code","colab":{}},"source":["# Apply softmax to logists to get probability distributions\n","probabilities = F.softmax(output, dim=1)\n","prediction = np.argmax(probabilities)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1VJfJYyd2Wn","colab_type":"code","outputId":"b8e9f350-477f-4608-84a4-d259a76679aa","executionInfo":{"status":"ok","timestamp":1584314073880,"user_tz":240,"elapsed":47938,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["prediction.item()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"code","metadata":{"id":"3FNqYgxocw6_","colab_type":"code","outputId":"30f57836-6de3-4a42-833a-49dd40fcf2e4","executionInfo":{"status":"ok","timestamp":1584314073881,"user_tz":240,"elapsed":47910,"user":{"displayName":"Laura Dang","photoUrl":"","userId":"16378619414378403353"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["plt.imshow(images[0].numpy().squeeze())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fe9af3859b0>"]},"metadata":{"tags":[]},"execution_count":99},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8mMAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}